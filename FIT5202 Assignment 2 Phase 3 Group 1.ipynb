{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    "Title:      FIT5202 Assessment 2 Phase 3 Group 1\n",
    "Author:     Marcus Hudson, Chee Wong, Ertan Yesilnacar, Mike Abecina\n",
    "Student ID: 30555094\n",
    "Due Date:   09/06/2020\n",
    "Task:       Data Wrangling of 2018 airbnb listings (Sydney) and Machine Learning Pipeline\n",
    "Source:     listings_dec18.csv\n",
    "Output:     Assessment_2_Wrangled.csv\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://c733cb369a3b:4040\n",
       "SparkContext available as 'sc' (version = 2.4.5, master = local[*], app id = local-1591599937007)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import scala.io.Source\n",
       "import java.io.BufferedWriter\n",
       "import java.io._\n",
       "import scala.collection.mutable.ArrayBuffer\n",
       "import org.apache.spark.ml.regression.{LinearRegression, LinearRegressionModel}\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.feature.{StringIndexer, StringIndexerModel}\n",
       "import org.apache.spark.ml.feature.VectorAssembler\n",
       "import org.apache.spark.ml.feature.{OneHotEncoderEstimator, StringIndexer}\n",
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
       "import org.apache.spark.ml.tuning.ParamGridBuilder\n",
       "import org.apache.spark.ml.tuning.{CrossValidator, CrossValidatorModel}\n",
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.mllib.evaluation.RegressionMetrics\n",
       "import org.apache.log4j.Logger\n",
       "import org.a..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.io.Source\n",
    "import java.io.BufferedWriter\n",
    "import java.io._\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import org.apache.spark.ml.regression.{LinearRegression, LinearRegressionModel}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.feature.{ StringIndexer, StringIndexerModel}\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.feature.{OneHotEncoderEstimator, StringIndexer}\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.tuning.ParamGridBuilder\n",
    "import org.apache.spark.ml.tuning.{CrossValidator, CrossValidatorModel}\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.mllib.evaluation.RegressionMetrics\n",
    "import org.apache.log4j.Logger\n",
    "import org.apache.log4j.Level\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.linalg.{Vector, Vectors}\n",
    "import org.apache.spark.ml.param.ParamMap\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.ml.feature.{ StringIndexer, StringIndexerModel}\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.sql.functions.when\n",
    "\n",
    "// Set log level to ERROR (less verbose)\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rawArrayLength: Int = 1000\n",
       "totalColumns: Int = 95\n",
       "rawArray: Array[Array[String]] = Array(Array(12351, https://www.airbnb.com/rooms/12351, 2.01812E+13, 12/7/2018, Sydney City & Harbour at the door, Come stay with Vinh & Stuart (Awarded as one of Australia's top hosts by Airbnb CEO Brian Chesky & key shareholder Ashton Kutcher. We're Sydney's #1 reviewed hosts too). Find out why we've been positively reviewed 500+ times. Message us and talk first BEFORE you make any reservation request - And please read our listing to the end (hint hint). Everything you need to know is there., \"We're pretty relaxed hosts, and we fully appreciate staying with someone else, in their home home, is not for every-one. This is not a business, or a hotel. We're casual Airbnb hosts, not hoteliers. If you're just ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Load Listings\n",
    "val rawArrayLength:Int = 1000 //36662 // hard-coded due to problem counting records in the file, caused by end of line\n",
    "val totalColumns = 95\n",
    "val rawArray = Array.ofDim[String](rawArrayLength, totalColumns) // Raw array to import source data\n",
    "var count = 0\n",
    "val fileName = \"listings_dec18.csv\"\n",
    "\n",
    "// Load each line from the file and remove commas inside double-quoted text fields\n",
    "for (line <- Source.fromFile(fileName, \"UTF-8\").getLines.drop(1).take(rawArrayLength)) { // Ignore header row .take(5000)\n",
    "    var count_2 = -1\n",
    "    if (count%1000 == 0) println(count)\n",
    "    //println(line)\n",
    "    line.split(\",(?=([^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\").foreach(colValue=> {count_2 += 1; rawArray(count)(count_2) = colValue}) // Don't split commas inside quotes\n",
    "    count += 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colListingID: Int = 0\n",
       "colHostResponseRate: Int = 25\n",
       "colCity: Int = 40\n",
       "colZipCode: Int = 42\n",
       "colPropertyType: Int = 50\n",
       "colRoomType: Int = 51\n",
       "colAccomodates: Int = 52\n",
       "colBathrooms: Int = 53\n",
       "colBedrooms: Int = 54\n",
       "colBeds: Int = 55\n",
       "colBedType: Int = 56\n",
       "colAmenities: Int = 57\n",
       "colPrice: Int = 59\n",
       "colAvailability365: Int = 73\n",
       "colNumberofReviews: Int = 75\n",
       "colReviewsScoreRating: Int = 78\n",
       "colCancellationPolicy: Int = 90\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colListingID = 0\n",
    "val colHostResponseRate = 25\n",
    "val colCity = 40\n",
    "val colZipCode = 42\n",
    "val colPropertyType = 50\n",
    "val colRoomType = 51\n",
    "val colAccomodates = 52\n",
    "val colBathrooms = 53\n",
    "val colBedrooms = 54\n",
    "val colBeds = 55\n",
    "val colBedType = 56\n",
    "val colAmenities = 57\n",
    "val colPrice = 59\n",
    "val colAvailability365 = 73\n",
    "val colNumberofReviews = 75\n",
    "val colReviewsScoreRating = 78 \n",
    "val colCancellationPolicy = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total eol fail records: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fails: Int = 0\n",
       "listingsArrayLength: Int = 36662\n",
       "listingsArrayToPos: Int = 999\n",
       "listingsArray: Array[Array[String]] = Array(Array(12351, https://www.airbnb.com/rooms/12351, 2.01812E+13, 12/7/2018, Sydney City & Harbour at the door, Come stay with Vinh & Stuart (Awarded as one of Australia's top hosts by Airbnb CEO Brian Chesky & key shareholder Ashton Kutcher. We're Sydney's #1 reviewed hosts too). Find out why we've been positively reviewed 500+ times. Message us and talk first BEFORE you make any reservation request - And please read our listing to the end (hint hint). Everything you need to know is there., \"We're pretty relaxed hosts, and we fully appreciate staying with someone else, in their home home, is not for every-one. This is not a business, or a hotel. We're casual Airbnb host..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Cleanup any fail records caused by end of line problem (\"\\n\") and extract an exact count of clean records\n",
    "var fails = 0\n",
    "for (i <- 0 to rawArrayLength - 1) {\n",
    "    val x = rawArray(i)(0)\n",
    "    if (!x.forall(_.isDigit)) {\n",
    "        fails += 1\n",
    "    }\n",
    "}\n",
    "println(\"Total eol fail records: \" + fails)\n",
    "\n",
    "// Move raw data to cleaned listings array\n",
    "val listingsArrayLength = 36662\n",
    "var listingsArrayToPos = -1\n",
    "val listingsArray = Array.ofDim[String](listingsArrayLength, 95)\n",
    "var cleanRecords = 0\n",
    "for (i <- 0 to rawArrayLength - 1) {\n",
    "    val x = rawArray(i)(0)\n",
    "    if (x.forall(_.isDigit)) {\n",
    "        listingsArrayToPos += 1\n",
    "        if (listingsArrayToPos < 36662) {\n",
    "            cleanRecords += 1\n",
    "            listingsArray(listingsArrayToPos) = rawArray(i)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewArray: Array[Array[String]] = Array(Array(2009Townhouse1, 191, 2), Array(2093House3, 296, 3), Array(2010Apartment1, 2050, 22), Array(2041House4, 179, 2), Array(2023Apartment1, 358, 4), Array(2060Apartment0, 97, 1), Array(2026Guest suite1, 87, 1), Array(2010Loft1, 476, 5), Array(2026House5, 95, 1), Array(2026Apartment2, 4705, 52), Array(2026Apartment1, 4321, 46), Array(2088House1, 190, 2), Array(2015House4, 93, 1), Array(2107Guesthouse0, 97, 1), Array(2066House1, 383, 4), Array(2015House1, 184, 2), Array(2021Apartment1, 722, 8), Array(2011Apartment1, 2705, 29), Array(2204House2, 196, 2), Array(2155Villa1, 100, 1), Array(2126House2, 98, 1), Array(2031Apartment2, 371, 4), Array(2034Villa5, 98, 1), Array(2036Apartment1, 98, 1), Array(2031House1, 389, 4), Array(2011Apartment3, 89, 1), ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create an array of review scores based on postcode, property_type and bedrooms that can be used to fill blank review scores\n",
    "var reviewArray = Array.ofDim[String](3000, 3) // columns are key, sum, count\n",
    "var reviewItems = 0\n",
    "for (rec <- 0 to cleanRecords - 1) {\n",
    "    val zipCode = listingsArray(rec)(colZipCode)\n",
    "    val propertyType = listingsArray(rec)(colPropertyType)\n",
    "    val bedrooms = listingsArray(rec)(colBedrooms)\n",
    "    val reviewsScoreRating = listingsArray(rec)(colReviewsScoreRating)\n",
    "    if (zipCode != \"\" && propertyType != \"\" && bedrooms != \"\" && reviewsScoreRating != \"\") {\n",
    "        val key = zipCode + propertyType + bedrooms\n",
    "        var key_found = false\n",
    "        for (revRec <- 0 to reviewItems) {\n",
    "            if (reviewArray(revRec)(0) == key) { // Key matched, update key record sum and count\n",
    "                val existingSum = reviewArray(revRec)(1).toInt\n",
    "                val count = reviewArray(revRec)(2).toInt\n",
    "                reviewArray(revRec)(1) = (existingSum+reviewsScoreRating.toInt).toString\n",
    "                reviewArray(revRec)(2) = (count+1).toString\n",
    "                key_found = true\n",
    "            }\n",
    "        }\n",
    "        if (!key_found) { // Create array record when no matching key can be found\n",
    "                reviewArray(reviewItems)(0) = key\n",
    "                reviewArray(reviewItems)(1) = reviewsScoreRating\n",
    "                reviewArray(reviewItems)(2) = \"1\"\n",
    "                reviewItems += 1\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zipArray: Array[Array[String]] = Array(Array(2009Pyrmont, 2009, Pyrmont, 10), Array(2093Balgowlah, 2093, Balgowlah, 7), Array(2010Darlinghurst, 2010, Darlinghurst, 34), Array(2041Balmain, 2041, Balmain, 11), Array(2023Bellevue Hill, 2023, Bellevue Hill, 13), Array(2060North Sydney, 2060, North Sydney, 9), Array(2026North Bondi, 2026, North Bondi, 37), Array(2026Bondi Beach, 2026, Bondi Beach, 64), Array(2088Mosman, 2088, Mosman, 13), Array(2022Bondi Junction, 2022, Bondi Junction, 19), Array(2015Alexandria, 2015, Alexandria, 7), Array(2107Avalon, 2107, Avalon, 13), Array(2026Sydney, 2026, Sydney, 5), Array(2066Lane Cove West, 2066, Lane Cove West, 1), Array(2021Paddington, 2021, Paddington, 15), Array(2011Elizabeth Bay, 2011, Elizabeth Bay, 6), Array(2204Marrickville, 2204, Marrickville..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create an array of city and zip to fill blank city and zip\n",
    "\n",
    "var zipArray = Array.ofDim[String](1000, 4) // columns are key, zipcode, city, count\n",
    "var zipItems = 0\n",
    "for (rec <- 0 to cleanRecords - 1) {\n",
    "    val city = listingsArray(rec)(colCity)\n",
    "    val zipCode = listingsArray(rec)(colZipCode)\n",
    "    if (zipCode != \"\" && city != \"\") {\n",
    "        val key = zipCode + city\n",
    "        var key_found = false\n",
    "        for (zipRec <- 0 to zipItems) {\n",
    "            if (zipArray(zipRec)(0) == key) { // Key matched, update key record count\n",
    "                val existingCount = zipArray(zipRec)(3).toInt\n",
    "                zipArray(zipRec)(3) = (existingCount+1).toString\n",
    "                key_found = true\n",
    "            }\n",
    "        }\n",
    "        if (!key_found) { // Create array record when no matching key can be found\n",
    "            zipArray(zipItems)(0) = key\n",
    "            zipArray(zipItems)(1) = zipCode\n",
    "            zipArray(zipItems)(2) = city\n",
    "            zipArray(zipItems)(3) = \"1\"\n",
    "            zipItems += 1\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discard invalid response rate: 473\n",
      "Discard weird city characters: 0\n",
      "Discard cannot determine city: 0\n",
      "Discard cannot determine zipcode: 0\n",
      "Discard listing has no availability: 11\n",
      "Discard cannot determine review score: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "file: java.io.File = Assessment_2_Wrangled.csv\n",
       "bw: java.io.BufferedWriter = java.io.BufferedWriter@3af7ac10\n",
       "propertyTypeHouse: List[String] = List(apartment, bungalow, cabin, casa particular (cuba), chalet, condominium, cottage, dome house, earth house, farm stay, guest suite, guesthouse, house, tiny house, townhouse, villa)\n",
       "propertyTypeHotel: List[String] = List(aparthotel, bed and breakfast, boutique hotel, heritage hotel (india), hostel, hotel, resort, serviced apartment)\n",
       "BedTypeList: List[String] = List(real bed)\n",
       "discardResponse: Int = 473\n",
       "discardWeirdCityChar: Int = 0\n",
       "discardNoCity: Int = 0\n",
       "discardNoZip: Int = 0\n",
       "discardNoAvailability: Int = 11\n",
       "discardNoScore: Int = 1\n",
       "colsToWrite: List[Int] = List(0, 25, 40, 42, 50, 51, 52, 53, 54, 55, 56, 57, 59, 73, 75, 78, 90)\n",
       "colHeaders: String ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Wrangle Listings and Write output file of wrangled data\n",
    "// Process the list of chosen column id's and if a column requires specific transformation, it will be listed in the main loop\n",
    "\n",
    "val file = new File(\"Assessment_2_Wrangled.csv\")\n",
    "val bw = new BufferedWriter(new FileWriter(file))\n",
    "val propertyTypeHouse = List(\"apartment\",\"bungalow\",\"cabin\",\"casa particular (cuba)\",\"chalet\",\"condominium\",\"cottage\",\"dome house\",\"earth house\",\"farm stay\",\"guest suite\",\"guesthouse\",\"house\",\"tiny house\",\"townhouse\",\"villa\")\n",
    "val propertyTypeHotel = List(\"aparthotel\",\"bed and breakfast\",\"boutique hotel\",\"heritage hotel (india)\",\"hostel\",\"hotel\",\"resort\",\"serviced apartment\")\n",
    "val BedTypeList = List(\"real bed\")\n",
    "var discardResponse = 0\n",
    "var discardWeirdCityChar = 0\n",
    "var discardNoCity = 0\n",
    "var discardNoZip = 0\n",
    "var discardNoAvailability = 0\n",
    "var discardNoScore = 0\n",
    "val colsToWrite = List(colListingID, colHostResponseRate, colCity, colZipCode, colPropertyType, colRoomType, colAccomodates, colBathrooms, colBedrooms, colBeds, colBedType, colAmenities, colPrice, colAvailability365, colNumberofReviews, colReviewsScoreRating, colCancellationPolicy)\n",
    "    val colHeaders = \"listing_id,host_response_rate,city,zipcode,property_type,room_type,accommodates,bathrooms,bedrooms,beds,bed_type,wifi,kitchen,washer,cable_tv,price,availability_365,number_of_reviews,review_scores_rating,cancellation_policy,estimated_annual_revenue,no_bedrooms,amenities\\n\"\n",
    "val ordinary=(('a' to 'z') ++ ('A' to 'Z') ++ ('0' to '9') ++ (' ' to '/')).toSet  // To help filter out weird city characters\n",
    "def isOrdinary(s:String)=s.forall(ordinary.contains(_)) // To help filter out weird city characters\n",
    "\n",
    "bw.write(colHeaders) // Write header to output file\n",
    "for (rec <- 0 to cleanRecords - 1) { // Loop through every record in the clean listings array\n",
    "    // Set default values\n",
    "    var price = 0.00\n",
    "    var available365 = 0\n",
    "    var outLine:String = \"\" // Line to write to output file\n",
    "    var WriteRecord = true\n",
    "    var propertyType = \"\"\n",
    "    var bedRooms = \"\"\n",
    "    var Accomodates = \"\"\n",
    "    var ListingID = \"\"\n",
    "    var bathroom_tmp = 0\n",
    "    var no_bedrooms = 0\n",
    "    var newAmenities = \"\"\n",
    "    \n",
    "    for (col <- 0 to totalColumns - 1) { // Loop through each column in the listing row\n",
    "        if (colsToWrite.contains(col)) { // Only process columns that we have chosen for output\n",
    "            if (col == colListingID) ListingID = listingsArray(rec)(col) // Listing ID\n",
    "            if (col == colHostResponseRate) { // host_response_rate\n",
    "                if (listingsArray(rec)(col) != \"N/A\" & listingsArray(rec)(col) != \"\") { // Discard if \"NA\" or NULL\n",
    "                    val hostResponseRate = listingsArray(rec)(col).replace(\"%\",\"\") // Remove percentage sign\n",
    "                    outLine = outLine + \",\" + hostResponseRate\n",
    "                }\n",
    "                else {\n",
    "                    if (WriteRecord) discardResponse += 1\n",
    "                    WriteRecord = false // Discard records with \"N/A\" or NULL\n",
    "                }\n",
    "            }\n",
    "            else if (col == colCity) { // city\n",
    "                var city = listingsArray(rec)(col)\n",
    "                if (!isOrdinary(city)) {  // Discard records with weird characters\n",
    "                    if (WriteRecord) discardWeirdCityChar += 1\n",
    "                    WriteRecord = false\n",
    "                }\n",
    "                else if (city == \"\") {\n",
    "                    val zipCode = listingsArray(rec)(colZipCode)\n",
    "                    if (zipCode != \"\") {\n",
    "                        var maxCount = 0\n",
    "                        for (n <- 0 to zipItems - 1) {\n",
    "                            val ArrayZip = zipArray(n)(1)\n",
    "                            val ArrayCity = zipArray(n)(2)\n",
    "                            val ArrayCount = zipArray(n)(3).toInt\n",
    "                            if (ArrayZip == zipCode) {\n",
    "                                if (count.toInt > maxCount) {\n",
    "                                    city = ArrayCity\n",
    "                                    maxCount = ArrayCount\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                    if (city == \"\") {\n",
    "                        if (WriteRecord) discardNoCity += 1\n",
    "                        WriteRecord = false // Discard records where we can;t find the city\n",
    "                    }\n",
    "                }\n",
    "                if (WriteRecord) outLine = outLine + \",\" + city\n",
    "            }\n",
    "            else if (col == colZipCode) { // zipcode\n",
    "                var zipCode = listingsArray(rec)(col)\n",
    "                if (zipCode == \"\") {\n",
    "                    val city = listingsArray(rec)(colCity)\n",
    "                    if (city != \"\") {\n",
    "                        var maxCount = 0\n",
    "                        for (n <- 0 to zipItems - 1) { // Use the city/zip array to find the most common match\n",
    "                            val Arrayzip = zipArray(n)(1)\n",
    "                            val ArrayCity = zipArray(n)(2)\n",
    "                            val ArrayCount = zipArray(n)(3).toInt\n",
    "                            if (ArrayCity == city) {\n",
    "                                if (count.toInt > maxCount) {\n",
    "                                    zipCode = Arrayzip\n",
    "                                    maxCount = ArrayCount\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                    if (zipCode == \"\") {\n",
    "                        if (WriteRecord) discardNoZip += 1\n",
    "                        WriteRecord = false // Discard records where we can't find the zipcode\n",
    "                    }\n",
    "                }\n",
    "                if (zipCode.length > 4) zipCode = zipCode.substring(zipCode.length-4, zipCode.length) // Final zipcode cleanup\n",
    "                if (WriteRecord) outLine = outLine + \",\" + zipCode\n",
    "            }\n",
    "            else if (col == colPropertyType) { // property_type\n",
    "                propertyType = listingsArray(rec)(col).toLowerCase() // Convert property type to 1 of 3 nominal values\n",
    "                if (propertyTypeHotel.contains(propertyType)) {\n",
    "                    outLine = outLine + \",hotel\"\n",
    "                }\n",
    "                else if (propertyTypeHouse.contains(propertyType)) {\n",
    "                    outLine = outLine + \",house\"\n",
    "                }\n",
    "                else {\n",
    "                    outLine = outLine + \",other\"\n",
    "                }\n",
    "            }\n",
    "            else if (col == colAccomodates) { // accommodates\n",
    "                Accomodates = listingsArray(rec)(col)\n",
    "                outLine = outLine + \",\" + Accomodates\n",
    "            }\n",
    "            else if (col == colBathrooms) { // bathrooms\n",
    "                var bathRooms = listingsArray(rec)(col)\n",
    "                if (bathRooms == \"\") {\n",
    "                    if (propertyTypeHotel.contains(propertyType)) bathRooms = \"1\" // Set empty bathrooms to 1 for hotel\n",
    "                    else if (propertyTypeHouse.contains(propertyType)) bathRooms = \"1\" // Set empty bathrooms to 1 for house\n",
    "                    else bathRooms = \"0\" // Set empty bathrooms to 0 for other property type\n",
    "                }\n",
    "                // Temporary calculated column bathroom_tmp\n",
    "                val bathInt = bathRooms.toFloat\n",
    "                if (bathInt > 2) bathroom_tmp = 3\n",
    "                else if (bathInt > 1) bathroom_tmp = 2\n",
    "                else if (bathInt > 0) bathroom_tmp = 1\n",
    "                else bathroom_tmp = 0\n",
    "\n",
    "                outLine = outLine + \",\" + bathRooms\n",
    "            }\n",
    "            else if (col == colBedrooms) { // bedrooms\n",
    "                bedRooms = listingsArray(rec)(col)\n",
    "                if (bedRooms == \"\") {\n",
    "                    val beds = listingsArray(rec)(col+1)\n",
    "                    if (beds != \"\") bedRooms = beds // Set empty bedrooms to number of beds\n",
    "                    else bedRooms = Accomodates // Set empty bedrooms to number of people that can be accomodated\n",
    "                }\n",
    "                // Calculated column no_bedrooms\n",
    "                val bedInt = bedRooms.toInt\n",
    "                if (bedInt > 3) no_bedrooms = 4\n",
    "                else if (bedInt > 2) no_bedrooms = 3\n",
    "                else if (bedInt > 1) no_bedrooms = 2\n",
    "                else no_bedrooms = 1\n",
    "\n",
    "                outLine = outLine + \",\" + bedRooms\n",
    "            }\n",
    "            else if (col == colBeds) { // beds\n",
    "                var beds = listingsArray(rec)(col)\n",
    "                if (beds == \"\") {\n",
    "                    if (bedRooms != \"\") {\n",
    "                        beds = bedRooms // Set empty beds to number of bedrooms\n",
    "                    }\n",
    "                }\n",
    "                outLine = outLine + \",\" + beds\n",
    "            }   \n",
    "            else if (col == colBedType) { // bed_type\n",
    "                val bedType = listingsArray(rec)(col).toLowerCase()  // Convert bed type to 1 of 2 nominal values\n",
    "                if (BedTypeList.contains(bedType)) {\n",
    "                    outLine = outLine + \",real bed\"\n",
    "                }\n",
    "                else {\n",
    "                    outLine = outLine + \",other\"\n",
    "                }\n",
    "            }\n",
    "            else if (col == colAmenities) { // amenities\n",
    "                val amenities = listingsArray(rec)(col).toLowerCase()\n",
    "                \n",
    "                // New calculated amenities column\n",
    "                newAmenities = bathroom_tmp.toString\n",
    "                \n",
    "                // Ordinal: Check amenities string for wifi, kitchen, washer and cable tv and set to 1 if found, otherwise 0\n",
    "                if (amenities.contains(\"wifi\")) {\n",
    "                    outLine = outLine + \",1\"\n",
    "                }\n",
    "                else outLine = outLine + \",0\"\n",
    "                if (amenities.contains(\"kitchen\")) {\n",
    "                    outLine = outLine + \",1\"\n",
    "                }\n",
    "                else outLine = outLine + \",0\"\n",
    "                if (amenities.contains(\"washer\")) {\n",
    "                    outLine = outLine + \",1\"\n",
    "                }\n",
    "                else outLine = outLine + \",0\"\n",
    "                if (amenities.contains(\"cable tv\")) {\n",
    "                    outLine = outLine + \",1\"\n",
    "                }\n",
    "                else outLine = outLine + \",0\"\n",
    "\n",
    "                if (amenities.contains(\"kitchen\")) newAmenities += \"1\" else newAmenities += \"0\"\n",
    "                if (amenities.contains(\"wifi\")) newAmenities += \"1\" else newAmenities += \"0\"\n",
    "            }\n",
    "            else if (col == colPrice) { // price\n",
    "                // Remove unwanted characters from the price string to transform to a double\n",
    "                var priceVal = listingsArray(rec)(col).toString.replace(\",\",\"\").replace(\"$\",\"\").replace(\"\\\"\", \"\").trim()\n",
    "                outLine = outLine + \",\" + priceVal\n",
    "                price = priceVal.toDouble\n",
    "            }\n",
    "            else if (col == colAvailability365) { // availability_365\n",
    "                val newVal = listingsArray(rec)(col)\n",
    "                if (newVal != \"0\") { // Discard listings that have no availability\n",
    "                    outLine = outLine + \",\" + newVal\n",
    "                    available365 = newVal.toInt\n",
    "                }\n",
    "                else {\n",
    "                    if (WriteRecord) discardNoAvailability += 1\n",
    "                    WriteRecord = false\n",
    "                }\n",
    "            }\n",
    "            else if (col == colReviewsScoreRating) { // reviews_score_rating\n",
    "                var score = listingsArray(rec)(col)\n",
    "                val reviews = listingsArray(rec)(colNumberofReviews)\n",
    "\n",
    "                if (score == \"\") {\n",
    "                    if (reviews == \"0\") score = \"0\" // Set empty review score to 0 where the listing has 0 reviews\n",
    "                    else { // Use the average review score array to match by property type, zipcode and number of bedrooms\n",
    "                        val zipCode = listingsArray(rec)(colZipCode)\n",
    "                        val propertyType = listingsArray(rec)(colPropertyType)\n",
    "                        val bedrooms = listingsArray(rec)(colBedrooms)\n",
    "                        val key = zipCode + propertyType + bedrooms\n",
    "                        var keyFound = false\n",
    "                        for (revRec <- 0 to reviewItems) {\n",
    "                            if (reviewArray(revRec)(0) == key) {\n",
    "                                val avg:Int = reviewArray(revRec)(1).toInt / reviewArray(revRec)(2).toInt\n",
    "                                score = avg.toString\n",
    "                                listingsArray(rec)(col) = score\n",
    "                                keyFound = true\n",
    "                            }\n",
    "                        }\n",
    "                        if (!keyFound) {\n",
    "                            if (WriteRecord) discardNoScore += 1\n",
    "                            WriteRecord = false  // Discard as there is no review information available\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                outLine = outLine + \",\" + score\n",
    "            }\n",
    "            else if (col == colCancellationPolicy) { // cancellation_policy\n",
    "                var cancellationPolicy = listingsArray(rec)(col).toLowerCase()\n",
    "                // Convert cancellation policies that begin with strict and super strict to strict\n",
    "                if (cancellationPolicy.substring(0,6) == \"strict\" || cancellationPolicy.substring(0,5) == \"super\") cancellationPolicy = \"strict\"\n",
    "                outLine = outLine + \",\" + cancellationPolicy\n",
    "            }\n",
    "            else { // Default for columns that require no transformation\n",
    "                if (col != 0) {\n",
    "                    outLine = outLine + \",\"\n",
    "                }\n",
    "                outLine = outLine + listingsArray(rec)(col)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    val annualRevenue = (365 - available365) * price // Calculate annual revenue for the listing based on price and availability\n",
    "    outLine += \",\" + f\"$annualRevenue%1.2f\"\n",
    "    \n",
    "    // Add extra calculated columns to the end of the line\n",
    "    outLine += \",\" + no_bedrooms.toString + \",\" + newAmenities\n",
    "\n",
    "    outLine += \"\\n\"\n",
    "    if (WriteRecord) bw.write(outLine)\n",
    "}\n",
    "bw.close()\n",
    "println(\"Discard invalid response rate: \" + discardResponse)\n",
    "println(\"Discard weird city characters: \" + discardWeirdCityChar)\n",
    "println(\"Discard cannot determine city: \" + discardNoCity)\n",
    "println(\"Discard cannot determine zipcode: \" + discardNoZip)\n",
    "println(\"Discard listing has no availability: \" + discardNoAvailability)\n",
    "println(\"Discard cannot determine review score: \" + discardNoScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object SparkSessionCreate\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create new Spark session\n",
    "object SparkSessionCreate {\n",
    "  def createSession(): SparkSession = {\n",
    "    val spark = SparkSession\n",
    "      .builder\n",
    "      .master(\"local[*]\")\n",
    "      .appName(s\"FIT5202Asessment02Phase03\")\n",
    "      .getOrCreate()\n",
    "\n",
    "    return spark\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customSchema: org.apache.spark.sql.types.StructType = StructType(StructField(listing_id,StringType,true), StructField(host_response_rate,IntegerType,true), StructField(city,StringType,true), StructField(zipcode,StringType,true), StructField(property_type,StringType,true), StructField(room_type,StringType,true), StructField(accommodates,IntegerType,true), StructField(bathrooms,DoubleType,true), StructField(bedrooms,IntegerType,true), StructField(beds,IntegerType,true), StructField(bed_type,StringType,true), StructField(wifi,IntegerType,true), StructField(kitchen,IntegerType,true), StructField(washer,IntegerType,true), StructField(cable_tv,IntegerType,true), StructField(price,DoubleType,true), StructField(availability_365,IntegerType,true), StructField(number_of_reviews,IntegerType,true),..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Customer schema to force column type\n",
    "val customSchema = StructType(\n",
    "  Array(\n",
    "    StructField(\"listing_id\", StringType, true),\n",
    "    StructField(\"host_response_rate\", IntegerType, true),\n",
    "    StructField(\"city\", StringType, true),\n",
    "    StructField(\"zipcode\", StringType, true),\n",
    "    StructField(\"property_type\", StringType, true),\n",
    "    StructField(\"room_type\", StringType, true),\n",
    "    StructField(\"accommodates\", IntegerType, true),\n",
    "    StructField(\"bathrooms\", DoubleType, true),\n",
    "    StructField(\"bedrooms\", IntegerType, true),\n",
    "    StructField(\"beds\", IntegerType, true),\n",
    "    StructField(\"bed_type\", StringType, true),\n",
    "    StructField(\"wifi\", IntegerType, true),\n",
    "    StructField(\"kitchen\", IntegerType, true),\n",
    "    StructField(\"washer\", IntegerType, true),\n",
    "    StructField(\"cable_tv\", IntegerType, true),\n",
    "    StructField(\"price\", DoubleType, true),\n",
    "    StructField(\"availability_365\", IntegerType, true),\n",
    "    StructField(\"number_of_reviews\", IntegerType, true),\n",
    "    StructField(\"review_scores_rating\", IntegerType, true),\n",
    "    StructField(\"cancellation_policy\", StringType, true),\n",
    "    StructField(\"estimated_annual_revenue\", DoubleType, true),\n",
    "    StructField(\"no_bedrooms\", IntegerType, true),\n",
    "    StructField(\"amenities\", IntegerType, true)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object Preprocessing\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object Preprocessing {\n",
    "    // Shuffling and preparing the data\n",
    "    var initialSample = 1.0\n",
    "\n",
    "    //val spark = SparkSessionCreate.createSession()\n",
    "    val wrangledData = \"Assessment_2_Wrangled.csv\"\n",
    "    \n",
    "    val spark = SparkSessionCreate.createSession()\n",
    "    \n",
    "    import spark.implicits._\n",
    "\n",
    "    val dataInput = spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(customSchema)\n",
    "        .format(\"com.databricks.spark.csv\")\n",
    "        .load(wrangledData)\n",
    "\n",
    "    \n",
    "    // DATA ARRANGEMENT BEFORE THE SPLIT\n",
    "    // ============================================\n",
    "    \n",
    "    println(\"Preparing data for before the training\")\n",
    "    val dataArrange1 = dataInput.withColumn(\"property_code\", when(col(\"property_type\") === \"house\", lit(\"3\").cast(IntegerType))\n",
    "          .when(col(\"property_type\") === \"hotel\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange2 = dataArrange1.withColumn(\"room_code\", when(col(\"room_type\") === \"Entire home/apt\", lit(\"3\").cast(IntegerType))\n",
    "          .when(col(\"room_type\") === \"Private room\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange3 = dataArrange2.withColumn(\"bed_type_code\", when(col(\"bed_type\") === \"real bed\", lit(\"3\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange4 = dataArrange3.withColumn(\"cancellation_code\", when(col(\"cancellation_policy\") === \"strict\", lit(\"1\").cast(IntegerType))\n",
    "          .when(col(\"cancellation_policy\") === \"moderate\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"3\").cast(IntegerType)))\n",
    "\n",
    "    // filtering the data and remove rows we have defined in our EDA work\n",
    "    // Step 01:\n",
    "    val dataFilt = dataArrange4.filter(!(dataArrange4(\"no_bedrooms\") === 1 && dataArrange4(\"amenities\") === 111 && dataArrange4(\"price\") > 7500))\n",
    "\n",
    "    // Step 02:\n",
    "    var amenitiesList = List(211, 311)\n",
    "    val dataFiltered = dataFilt.filter(!(dataFilt(\"no_bedrooms\") === 3 && dataFilt(\"amenities\").isin(amenitiesList:_*) && dataFilt(\"price\") > 5000))\n",
    "    \n",
    "    // Drop unnecessary fields\n",
    "    val dataDrop = dataFiltered.drop(\"city\", \"listing_id\",\"property_type\", \"room_type\", \"cable_tv\", \"bed_type\", \"price\", \"cancellation_policy\")\n",
    "\n",
    "    var data = dataDrop.withColumnRenamed(\"estimated_annual_revenue\", \"label\").sample(false, initialSample)\n",
    "\n",
    "    \n",
    "    var DF = data.na.drop()\n",
    "\n",
    "    // Null check\n",
    "    if (data == DF)\n",
    "    println(\"No null values in the DataFrame\")\n",
    "\n",
    "    else {\n",
    "    println(\"Null values exist in the DataFrame\")\n",
    "    data = DF\n",
    "    }\n",
    "\n",
    "    println(data.printSchema())\n",
    "    data.select(\"zipcode\", \"label\", \"property_code\", \"room_code\", \"no_bedrooms\",  \n",
    "                \"accommodates\", \"amenities\", \"cancellation_code\", \"availability_365\").show()\n",
    "    \n",
    "    // ============================================\n",
    "    // TWO-STAGE SPLITTING \n",
    "    // ============================================\n",
    "    \n",
    "    // 1) Split the training data as train (training + validation) and test data\n",
    "    val seed = 12345L\n",
    "    val splits01 = data.randomSplit(Array(0.75, 0.25), seed)\n",
    "    val (trainData, testData) = (splits01(0), splits01(1))               \n",
    "    \n",
    "    // 2) Split the train data as training and validation data\n",
    "    val splits02 = trainData.randomSplit(Array(0.8, 0.2), seed)\n",
    "    val (trainingData, validationData) = (splits02(0), splits02(1))\n",
    "\n",
    "    // Caching all data for faster in-memory access\n",
    "    trainingData.cache\n",
    "    validationData.cache\n",
    "    testData.cache\n",
    "    \n",
    "    // ============================================\n",
    "    // DATA PIPELINE ARRANGEMENT\n",
    "    // ============================================\n",
    "    // Identify the categorical columns\n",
    "    def isCateg(c: String): Boolean = c matches \"zipcode\"\n",
    "\n",
    "    def categNewCol(c: String): String = if (isCateg(c)) s\"idx_${c}\" else c\n",
    "\n",
    "    // Function to select only feature columns (omit id and label)\n",
    "    def onlyFeatureCols(c: String): Boolean = !(c matches \"id|label|zipcode\")\n",
    "\n",
    "    // Definitive set of feature columns\n",
    "    val featureCols = trainingData.columns\n",
    "        .filter(onlyFeatureCols)\n",
    "        .map(categNewCol)\n",
    "\n",
    "    // StringIndexer for categorical columns (OneHotEncoder should be evaluated as well)\n",
    "    val stringIndexerStages = trainingData.columns.filter(isCateg)\n",
    "      .map(c => new StringIndexer()\n",
    "      .setInputCol(c)\n",
    "      .setOutputCol(categNewCol(c))\n",
    "      .fit(dataInput.select(c)))    \n",
    "    \n",
    "      // VectorAssembler for training features\n",
    "      val assembler = new VectorAssembler()\n",
    "        .setInputCols(featureCols)\n",
    "        .setOutputCol(\"features\")\n",
    "    // ============================================    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ML pipeline\n",
      "Preparing data for before the training\n",
      "Null values exist in the DataFrame\n",
      "root\n",
      " |-- host_response_rate: integer (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- accommodates: integer (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- beds: integer (nullable = true)\n",
      " |-- wifi: integer (nullable = true)\n",
      " |-- kitchen: integer (nullable = true)\n",
      " |-- washer: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- review_scores_rating: integer (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- no_bedrooms: integer (nullable = true)\n",
      " |-- amenities: integer (nullable = true)\n",
      " |-- property_code: integer (nullable = true)\n",
      " |-- room_code: integer (nullable = true)\n",
      " |-- bed_type_code: integer (nullable = true)\n",
      " |-- cancellation_code: integer (nullable = true)\n",
      "\n",
      "()\n",
      "+-------+--------+-------------+---------+-----------+------------+---------+-----------------+----------------+\n",
      "|zipcode|   label|property_code|room_code|no_bedrooms|accommodates|amenities|cancellation_code|availability_365|\n",
      "+-------+--------+-------------+---------+-----------+------------+---------+-----------------+----------------+\n",
      "|   2009| 17800.0|            3|        2|          1|           2|      101|                1|             187|\n",
      "|   2093| 20724.0|            3|        3|          3|           6|      311|                1|             321|\n",
      "|   2010|  5341.0|            3|        2|          1|           2|      111|                1|             316|\n",
      "|   2041|133200.0|            3|        3|          4|           8|      211|                1|              69|\n",
      "|   2088| 24920.0|            3|        3|          1|           4|      111|                2|             187|\n",
      "|   2015|126207.0|            3|        3|          4|           7|      311|                2|              32|\n",
      "|   2026| 59045.0|            3|        3|          2|           4|      111|                1|             124|\n",
      "|   2107|  3600.0|            3|        3|          1|           2|      111|                2|             341|\n",
      "|   2026| 64078.0|            3|        3|          2|           4|      111|                1|              43|\n",
      "|   2015| 23625.0|            3|        2|          1|           2|      111|                1|              50|\n",
      "|   2155|     0.0|            3|        2|          1|           2|      101|                3|             365|\n",
      "|   2126|  8455.0|            3|        2|          2|           4|      311|                3|             270|\n",
      "|   2101|  6104.0|            3|        3|          1|           2|      111|                2|             309|\n",
      "|   2031| 35140.0|            3|        3|          2|           4|      111|                1|             225|\n",
      "|   2009| 12816.0|            3|        2|          1|           2|      101|                1|             221|\n",
      "|   2036| 41760.0|            3|        3|          1|           3|      111|                2|              17|\n",
      "|   2011| 45731.0|            3|        3|          3|           6|      311|                1|             226|\n",
      "|   2089|  1008.0|            3|        2|          1|           1|      111|                3|             353|\n",
      "|   2024| 35695.0|            3|        3|          2|           4|      111|                1|             244|\n",
      "|   2065|     0.0|            3|        2|          1|           1|      111|                1|             365|\n",
      "+-------+--------+-------------+---------+-----------+------------+---------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Preparing K-fold Cross Validation and Grid Search: Model tuning\n",
      "Training model with Linear Regression algorithm\n",
      "Evaluating model on train and validation set and calculating RMSE\n",
      "\n",
      "=====================================================================\n",
      "Param trainSample: 1.0\n",
      "Param testSample: 1.0\n",
      "TrainingData count: 305\n",
      "ValidationData count: 76\n",
      "TestData count: 134\n",
      "=====================================================================\n",
      "Param maxIter = 1000\n",
      "Param numFolds = 10\n",
      "=====================================================================\n",
      "Training data MSE = 1.5624041697019165E9\n",
      "Training data RMSE = 39527.25856547499\n",
      "Training data R-squared = -0.09146884611633777\n",
      "Training data MAE = 20231.819172714608\n",
      "Training data Explained variance = 2.9939699621977973E9\n",
      "=====================================================================\n",
      "Validation data MSE = 2.1251047990367174E9\n",
      "Validation data RMSE = 46098.85897760071\n",
      "Validation data R-squared = -0.618766346612512\n",
      "Validation data MAE = 25006.59113291364\n",
      "Validation data Explained variance = 3.5310093056592674E9\n",
      "=====================================================================\n",
      "\n",
      "CV params explained: estimator: estimator for selection (current: pipeline_0266634ba08d)\n",
      "estimatorParamMaps: param maps for the estimator (current: [Lorg.apache.spark.ml.param.ParamMap;@31ce27c4)\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validated metric (current: regEval_12a1c05350e3)\n",
      "numFolds: number of folds for cross validation (>= 2) (default: 3, current: 10)\n",
      "seed: random seed (default: -1191137437)\n",
      "GBT params explained: aggregationDepth: suggested depth for treeAggregate (>= 2) (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty (default: 0.0, current: 1.0)\n",
      "epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. (default: 1.35)\n",
      "featuresCol: features column name (default: features, current: features)\n",
      "fitIntercept: whether to fit an intercept term (default: true)\n",
      "labelCol: label column name (default: label, current: label)\n",
      "loss: The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError) (default: squaredError)\n",
      "maxIter: maximum number of iterations (>= 0) (default: 100, current: 1000)\n",
      "predictionCol: prediction column name (default: prediction)\n",
      "regParam: regularization parameter (>= 0) (default: 0.0, current: 0.001)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto) (default: auto)\n",
      "standardization: whether to standardize the training features before fitting the model (default: true)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0) (default: 1.0E-6, current: 1.0E-6)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0 (undefined)\n",
      "\n",
      "=====================================================================\n",
      "\n",
      "(host_response_rate,46.359017773605345)\n",
      "(accommodates,1313.9345438041548)\n",
      "(bathrooms,46171.46584093541)\n",
      "(bedrooms,-10362.481031978556)\n",
      "(beds,-5965.23821882886)\n",
      "(wifi,-8962.681650434924)\n",
      "(kitchen,-7082.271761775696)\n",
      "(washer,4464.792482880548)\n",
      "(availability_365,-217.52378087237355)\n",
      "(number_of_reviews,-13.753258365485173)\n",
      "(review_scores_rating,74.48956782692503)\n",
      "(no_bedrooms,23549.659945147778)\n",
      "(amenities,-249.94389595762354)\n",
      "(property_code,3193.8722716623165)\n",
      "(room_code,14550.529336947633)\n",
      "(bed_type_code,2241.0384959742837)\n",
      "(cancellation_code,-4369.260370237758)\n",
      "Run prediction on the test set\n",
      "\n",
      "=====================================================================\n",
      "Test data MSE = 1.0057590521908779E9\n",
      "Test data RMSE = 31713.704485456725\n",
      "Test data R-squared = 0.5942561296976776\n",
      "Test data MAE = 18374.7917310745\n",
      "Test data Explained variance = 1.2468616243744204E9\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numFolds: Int = 10\n",
       "MaxIter: Seq[Int] = List(1000)\n",
       "RegParam: Seq[Double] = List(0.001)\n",
       "Tol: Seq[Double] = List(1.0E-6)\n",
       "ElasticNetParam: Seq[Double] = List(1.0)\n",
       "model: org.apache.spark.ml.regression.LinearRegression = linReg_35527320a16b\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_0266634ba08d\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlinReg_35527320a16b-elasticNetParam: 1.0,\n",
       "\tlinReg_35527320a16b-maxIter: 1000,\n",
       "\tlinReg_35527320a16b-regParam: 0.001,\n",
       "\tlinReg_35527320a16b-tol: 1.0E-6\n",
       "})\n",
       "cv: org.apache.spark.ml.tuning.CrossValidator = cv_aa18056717b0\n",
       "cvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_aa18056717b0\n",
       "trainPredictionsAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[704] at rdd at <console>:110\n",
       "validPredictionsAndLabels:..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Defining hyperparameters \n",
    "// number of folds for cross-validation\n",
    "\n",
    "val numFolds = 10\n",
    "// number of maximum iteration\n",
    "val MaxIter: Seq[Int] = Seq(1000)\n",
    "// regression parameter\n",
    "val RegParam: Seq[Double] = Seq(0.001)\n",
    "// the value of tolerance\n",
    "val Tol: Seq[Double] = Seq(1e-6)\n",
    "// finally, elastic network parameter\n",
    "val ElasticNetParam: Seq[Double] = Seq(1)\n",
    "\n",
    "// Create an LinerRegression estimator\n",
    "val model = new LinearRegression()\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setLabelCol(\"label\")\n",
    "\n",
    "// Building the Pipeline for transformations and predictor\n",
    "println(\"Building ML pipeline\")\n",
    "val pipeline = new Pipeline().setStages(Preprocessing.stringIndexerStages :+ Preprocessing.assembler :+ model)\n",
    "\n",
    "// ***********************************************************\n",
    "println(\"Preparing K-fold Cross Validation and Grid Search: Model tuning\")\n",
    "// ***********************************************************\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(model.maxIter, MaxIter)\n",
    "  .addGrid(model.regParam, RegParam)\n",
    "  .addGrid(model.tol, Tol)\n",
    "  .addGrid(model.elasticNetParam, ElasticNetParam)\n",
    "  .build()\n",
    "\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(new RegressionEvaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setNumFolds(numFolds)\n",
    "\n",
    "// ************************************************************\n",
    "println(\"Training model with Linear Regression algorithm\")\n",
    "// ************************************************************\n",
    "val cvModel = cv.fit(Preprocessing.trainingData)\n",
    "\n",
    "// Save the workflow\n",
    "cvModel.write.overwrite().save(\"model/LR_model\")\n",
    "\n",
    "// **********************************************************************\n",
    "println(\"Evaluating model on train and validation set and calculating RMSE\")\n",
    "// **********************************************************************\n",
    "val trainPredictionsAndLabels = cvModel.transform(Preprocessing.trainingData).select(\"label\", \"prediction\")\n",
    "  .map { case Row(label: Double, prediction: Double) => (label, prediction) }.rdd\n",
    "\n",
    "val validPredictionsAndLabels = cvModel.transform(Preprocessing.validationData).select(\"label\", \"prediction\")\n",
    "  .map { case Row(label: Double, prediction: Double) => (label, prediction) }.rdd  \n",
    "\n",
    "val trainRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)\n",
    "val validRegressionMetrics = new RegressionMetrics(validPredictionsAndLabels)\n",
    "val bestModel = cvModel.bestModel.asInstanceOf[PipelineModel]\n",
    "\n",
    "val results = \"\\n=====================================================================\\n\" +\n",
    "  s\"Param trainSample: ${Preprocessing.initialSample}\\n\" +\n",
    "  s\"Param testSample: ${Preprocessing.initialSample}\\n\" +\n",
    "  s\"TrainingData count: ${Preprocessing.trainingData.count}\\n\" +\n",
    "  s\"ValidationData count: ${Preprocessing.validationData.count}\\n\" +\n",
    "  s\"TestData count: ${Preprocessing.testData.count}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Param maxIter = ${MaxIter.mkString(\",\")}\\n\" +\n",
    "  s\"Param numFolds = ${numFolds}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Training data MSE = ${trainRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Training data RMSE = ${trainRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Training data R-squared = ${trainRegressionMetrics.r2}\\n\" +\n",
    "  s\"Training data MAE = ${trainRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Training data Explained variance = ${trainRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Validation data MSE = ${validRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Validation data RMSE = ${validRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Validation data R-squared = ${validRegressionMetrics.r2}\\n\" +\n",
    "  s\"Validation data MAE = ${validRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Validation data Explained variance = ${validRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\\n\" +\n",
    "  s\"CV params explained: ${cvModel.explainParams}\\n\" +\n",
    "  s\"GBT params explained: ${bestModel.stages.last.asInstanceOf[LinearRegressionModel].explainParams}\\n\" +\n",
    "  \"\\n=====================================================================\\n\"\n",
    "println(results)\n",
    "\n",
    "\n",
    "    val model_columns = Preprocessing.featureCols\n",
    "    val stages = bestModel.stages\n",
    "    val coefficients = stages(2).asInstanceOf[LinearRegressionModel].coefficients.toArray\n",
    "    val intercept = stages(2).asInstanceOf[LinearRegressionModel].intercept\n",
    "    val coefficient_value = model_columns zip coefficients\n",
    "    for (i<- 0 to 16){\n",
    "        println(coefficient_value(i))\n",
    "    }\n",
    "\n",
    "\n",
    "// *****************************************\n",
    "// Now see if we can predict values in our test data\n",
    "// Generate predictions using our linear regression model for all features in our test data\n",
    "println(\"Run prediction on the test set\")\n",
    "\n",
    "val fullPredictions = cvModel.transform(Preprocessing.testData).cache()\n",
    "\n",
    "// This basically adds a \"prediction\" column to our testDF dataframe\n",
    "\n",
    "// Extract the predictions and the \"known\" correct labels\n",
    "val testPredictionsAndLabels = fullPredictions.select(\"prediction\", \"label\").rdd.map(x => (x.getDouble(0), x.getDouble(1)))\n",
    "\n",
    "// Print out the predicted and actual values for each point\n",
    "/*\n",
    "for (prediction <- testPredictionsAndLabels) {\n",
    "  println(prediction)\n",
    "}\n",
    "*/\n",
    "\n",
    "val testRegressionMetrics = new RegressionMetrics(testPredictionsAndLabels)\n",
    "val testresults = \"\\n=====================================================================\\n\" +\n",
    "  s\"Test data MSE = ${testRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Test data RMSE = ${testRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Test data R-squared = ${testRegressionMetrics.r2}\\n\" +\n",
    "  s\"Test data MAE = ${testRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Test data Explained variance = ${testRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\"\n",
    "println(testresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object Preprocessing\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object Preprocessing {\n",
    "    // Shuffling and preparing the data\n",
    "    var initialSample = 1.0\n",
    "\n",
    "    //val spark = SparkSessionCreate.createSession()\n",
    "    val wrangledData = \"Assessment_2_Wrangled.csv\"\n",
    "    \n",
    "    val spark = SparkSessionCreate.createSession()\n",
    "    \n",
    "    import spark.implicits._\n",
    "\n",
    "    val dataInput = spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(customSchema)\n",
    "        .format(\"com.databricks.spark.csv\")\n",
    "        .load(wrangledData)\n",
    "    \n",
    "    // DATA ARRANGEMENT BEFORE THE SPLIT\n",
    "    // ============================================\n",
    "    \n",
    "    println(\"Preparing data for before the training\")\n",
    "    val dataArrange1 = dataInput.withColumn(\"property_code\", when(col(\"property_type\") === \"house\", lit(\"3\").cast(IntegerType))\n",
    "          .when(col(\"property_type\") === \"hotel\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange2 = dataArrange1.withColumn(\"room_code\", when(col(\"room_type\") === \"Entire home/apt\", lit(\"3\").cast(IntegerType))\n",
    "          .when(col(\"room_type\") === \"Private room\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange3 = dataArrange2.withColumn(\"bed_type_code\", when(col(\"bed_type\") === \"real bed\", lit(\"3\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange4 = dataArrange3.withColumn(\"cancellation_code\", when(col(\"cancellation_policy\") === \"strict\", lit(\"1\").cast(IntegerType))\n",
    "          .when(col(\"cancellation_policy\") === \"moderate\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"3\").cast(IntegerType)))\n",
    "    \n",
    "    // Taking natural logarithm of selected fields which are considered in our proposal and EDA work\n",
    "    val dataLog1 = dataArrange4.withColumn(\"log_estimated_annual_revenue\", log10(\"estimated_annual_revenue\"))\n",
    "    val dataLog2 = dataLog1.withColumn(\"log_accom\", log10(\"accommodates\"))\n",
    "    val dataLog3 = dataLog2.withColumn(\"log_rating\", log10(\"review_scores_rating\"))   \n",
    "\n",
    "    // Filtering the data and remove rows we have defined in our EDA work\n",
    "    // Step 01:\n",
    "    val dataFilt = dataLog3.filter(!(dataLog3(\"no_bedrooms\") === 1 && dataLog3(\"amenities\") === 111 && dataLog3(\"price\") > 7500))\n",
    "\n",
    "    // Step 02:\n",
    "    var amenitiesList = List(211, 311)\n",
    "    val dataFiltered = dataFilt.filter(!(dataFilt(\"no_bedrooms\") === 3 && dataFilt(\"amenities\").isin(amenitiesList:_*) && dataFilt(\"price\") > 5000))\n",
    "\n",
    "    \n",
    "    // Drop unnecessary fields\n",
    "    val dataDrop = dataFiltered.drop(\"property_type\", \"room_type\", \"cable_tv\", \"listing_id\",\n",
    "                                     \"bed_type\", \"cancellation_policy\", \"kitchen\", \"wifi\", \"cable_tv\",\n",
    "                                     \"host_response_rate\", \"bathrooms\", \"city\", \"estimated_annual_revenue\",\n",
    "                                     \"accommodates\", \"beds\", \"price\")\n",
    "   \n",
    "    var data = dataDrop.withColumnRenamed(\"log_estimated_annual_revenue\", \"label\").sample(false, initialSample)\n",
    "    \n",
    "    var DF = data.na.drop()\n",
    "\n",
    "    // Null check\n",
    "    if (data == DF)\n",
    "    println(\"No null values in the DataFrame\")\n",
    "\n",
    "    else {\n",
    "    println(\"Null values exist in the DataFrame\")\n",
    "    data = DF\n",
    "    }\n",
    "\n",
    "    println(data.printSchema())\n",
    "    data.select(\"zipcode\", \"label\", \"log_accom\", \"amenities\", \"log_rating\", \n",
    "                \"cancellation_code\", \"availability_365\").show()\n",
    "    \n",
    "    // ============================================\n",
    "    // TWO-STAGE SPLITTING \n",
    "    // ============================================\n",
    "    \n",
    "    // 1) Split the training data as train (training + validation) and test data\n",
    "    val seed = 12345L\n",
    "    val splits01 = data.randomSplit(Array(0.75, 0.25), seed)\n",
    "    val (trainData, testData) = (splits01(0), splits01(1))               \n",
    "    \n",
    "    // 2) Split the train data as training and validation data\n",
    "    val splits02 = trainData.randomSplit(Array(0.8, 0.2), seed)\n",
    "    val (trainingData, validationData) = (splits02(0), splits02(1))\n",
    "\n",
    "    // Caching all data for faster in-memory access\n",
    "    trainingData.cache\n",
    "    validationData.cache\n",
    "    testData.cache\n",
    "    \n",
    "    // ============================================\n",
    "    // DATA PIPELINE ARRANGEMENT\n",
    "    // ============================================\n",
    "    // Identify the categorical columns\n",
    "    def isCateg(c: String): Boolean = c matches \"zipcode\"\n",
    "\n",
    "    def categNewCol(c: String): String = if (isCateg(c)) s\"idx_${c}\" else c\n",
    "\n",
    "    // Function to select only feature columns (omit id and label)\n",
    "    def onlyFeatureCols(c: String): Boolean = !(c matches \"id|label|zipcode\")\n",
    "\n",
    "    // Definitive set of feature columns\n",
    "    val featureCols = trainingData.columns\n",
    "        .filter(onlyFeatureCols)\n",
    "        .map(categNewCol)\n",
    "\n",
    "    // StringIndexer for categorical columns (OneHotEncoder should be evaluated as well)\n",
    "    val stringIndexerStages = trainingData.columns.filter(isCateg)\n",
    "      .map(c => new StringIndexer()\n",
    "      .setInputCol(c)\n",
    "      .setOutputCol(categNewCol(c))\n",
    "      .fit(dataInput.select(c)))    \n",
    "    \n",
    "      // VectorAssembler for training features\n",
    "      val assembler = new VectorAssembler()\n",
    "        .setInputCols(featureCols)\n",
    "        .setOutputCol(\"features\")\n",
    "    // ============================================     \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ML pipeline\n",
      "Preparing data for before the training\n",
      "Null values exist in the DataFrame\n",
      "root\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- washer: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- review_scores_rating: integer (nullable = true)\n",
      " |-- no_bedrooms: integer (nullable = true)\n",
      " |-- amenities: integer (nullable = true)\n",
      " |-- property_code: integer (nullable = true)\n",
      " |-- room_code: integer (nullable = true)\n",
      " |-- bed_type_code: integer (nullable = true)\n",
      " |-- cancellation_code: integer (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- log_accom: double (nullable = true)\n",
      " |-- log_rating: double (nullable = true)\n",
      "\n",
      "()\n",
      "+-------+------------------+-------------------+---------+------------------+-----------------+----------------+\n",
      "|zipcode|             label|          log_accom|amenities|        log_rating|cancellation_code|availability_365|\n",
      "+-------+------------------+-------------------+---------+------------------+-----------------+----------------+\n",
      "|   2009| 4.250420002308894| 0.3010299956639812|      101|1.9777236052888478|                1|             187|\n",
      "|   2093| 4.316473583615084| 0.7781512503836436|      311|               2.0|                1|             321|\n",
      "|   2010| 3.727622577969137| 0.3010299956639812|      111|1.9444826721501687|                1|             316|\n",
      "|   2041| 5.124504224834283| 0.9030899869919435|      211|1.9822712330395684|                1|              69|\n",
      "|   2088| 4.396548037987132| 0.6020599913279624|      111| 1.954242509439325|                2|             187|\n",
      "|   2015| 5.101083443474392| 0.8450980400142568|      311| 1.968482948553935|                2|              32|\n",
      "|   2026| 4.771183126939401| 0.6020599913279624|      111|1.9344984512435677|                1|             124|\n",
      "|   2107|3.5563025007672873| 0.3010299956639812|      111|1.9867717342662448|                2|             341|\n",
      "|   2026| 4.806708948105538| 0.6020599913279624|      111|1.9493900066449128|                1|              43|\n",
      "|   2015| 4.373371817181301| 0.3010299956639812|      111| 1.968482948553935|                1|              50|\n",
      "|   2126|3.9271136119337604| 0.6020599913279624|      311|1.9912260756924949|                3|             270|\n",
      "|   2031| 4.545801757159277| 0.6020599913279624|      111|               2.0|                1|             225|\n",
      "|   2009| 4.107752498740163| 0.3010299956639812|      101|1.9822712330395684|                1|             221|\n",
      "|   2036| 4.620760489994206|0.47712125471966244|      111|1.9912260756924949|                2|              17|\n",
      "|   2011| 4.660210698204069| 0.7781512503836436|      311|1.9493900066449128|                1|             226|\n",
      "|   2089|3.0034605321095067|                0.0|      111|  1.99563519459755|                3|             353|\n",
      "|   2024| 4.552607386294613| 0.6020599913279624|      111|1.9822712330395684|                1|             244|\n",
      "|   2076|2.8926510338773004|                0.0|      111|1.9867717342662448|                3|             354|\n",
      "|   2041|3.7781512503836434| 0.7781512503836436|      211| 1.968482948553935|                1|             350|\n",
      "|   2026| 4.753368539509981| 0.6020599913279624|      111| 1.954242509439325|                1|              13|\n",
      "+-------+------------------+-------------------+---------+------------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Preparing K-fold Cross Validation and Grid Search: Model tuning\n",
      "Training model with Linear Regression algorithm\n",
      "Evaluating model on train and validation set and calculating RMSE\n",
      "\n",
      "=====================================================================\n",
      "Param trainSample: 1.0\n",
      "Param testSample: 1.0\n",
      "TrainingData count: 281\n",
      "ValidationData count: 74\n",
      "TestData count: 124\n",
      "=====================================================================\n",
      "Param maxIter = 1000\n",
      "Param numFolds = 10\n",
      "=====================================================================\n",
      "Training data MSE = 0.07372794984064471\n",
      "Training data RMSE = 0.2715289116109824\n",
      "Training data R-squared = 0.760118154594038\n",
      "Training data MAE = 0.2054898145039661\n",
      "Training data Explained variance = 0.383218774834418\n",
      "=====================================================================\n",
      "Validation data MSE = 0.09731989615257321\n",
      "Validation data RMSE = 0.31196136964786714\n",
      "Validation data R-squared = 0.6705868607182953\n",
      "Validation data MAE = 0.24383998314174302\n",
      "Validation data Explained variance = 0.4208436484710475\n",
      "=====================================================================\n",
      "\n",
      "CV params explained: estimator: estimator for selection (current: pipeline_528acd9e76f2)\n",
      "estimatorParamMaps: param maps for the estimator (current: [Lorg.apache.spark.ml.param.ParamMap;@41e74d01)\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validated metric (current: regEval_a3a6d73eea69)\n",
      "numFolds: number of folds for cross validation (>= 2) (default: 3, current: 10)\n",
      "seed: random seed (default: -1191137437)\n",
      "GBT params explained: aggregationDepth: suggested depth for treeAggregate (>= 2) (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty (default: 0.0, current: 1.0)\n",
      "epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. (default: 1.35)\n",
      "featuresCol: features column name (default: features, current: features)\n",
      "fitIntercept: whether to fit an intercept term (default: true)\n",
      "labelCol: label column name (default: label, current: label)\n",
      "loss: The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError) (default: squaredError)\n",
      "maxIter: maximum number of iterations (>= 0) (default: 100, current: 1000)\n",
      "predictionCol: prediction column name (default: prediction)\n",
      "regParam: regularization parameter (>= 0) (default: 0.0, current: 0.001)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto) (default: auto)\n",
      "standardization: whether to standardize the training features before fitting the model (default: true)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0) (default: 1.0E-6, current: 1.0E-6)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0 (undefined)\n",
      "\n",
      "=====================================================================\n",
      "\n",
      "(bedrooms,0.06462899045138858)\n",
      "(washer,-0.004180415168896542)\n",
      "(availability_365,-0.0037335472015003106)\n",
      "(number_of_reviews,5.953534697802819E-4)\n",
      "(review_scores_rating,0.013623489007389642)\n",
      "(no_bedrooms,0.0)\n",
      "(amenities,5.33591940409586E-4)\n",
      "(property_code,-0.11732481185800285)\n",
      "(room_code,0.4880178016871049)\n",
      "(bed_type_code,0.05647122086535056)\n",
      "(cancellation_code,-0.0010859220584427036)\n",
      "(log_accom,0.1326609120425136)\n",
      "(log_rating,-1.552136009225174)\n",
      "Run prediction on the test set\n",
      "\n",
      "=====================================================================\n",
      "Test data MSE = 0.10399486004865204\n",
      "Test data RMSE = 0.3224823406772099\n",
      "Test data R-squared = 0.7500690333088522\n",
      "Test data MAE = 0.2226162871601035\n",
      "Test data Explained variance = 0.2923850357507983\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numFolds: Int = 10\n",
       "MaxIter: Seq[Int] = List(1000)\n",
       "RegParam: Seq[Double] = List(0.001)\n",
       "Tol: Seq[Double] = List(1.0E-6)\n",
       "ElasticNetParam: Seq[Double] = List(1.0)\n",
       "model: org.apache.spark.ml.regression.LinearRegression = linReg_87a9d554c717\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_528acd9e76f2\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlinReg_87a9d554c717-elasticNetParam: 1.0,\n",
       "\tlinReg_87a9d554c717-maxIter: 1000,\n",
       "\tlinReg_87a9d554c717-regParam: 0.001,\n",
       "\tlinReg_87a9d554c717-tol: 1.0E-6\n",
       "})\n",
       "cv: org.apache.spark.ml.tuning.CrossValidator = cv_0d3a2db0721c\n",
       "cvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_0d3a2db0721c\n",
       "trainPredictionsAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[1468] at rdd at <console>:136\n",
       "validPredictionsAndLabels..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Defining hyperparameters \n",
    "// number of folds for cross-validation\n",
    "val numFolds = 10\n",
    "// number of maximum iteration\n",
    "val MaxIter: Seq[Int] = Seq(1000)\n",
    "// regression parameter\n",
    "val RegParam: Seq[Double] = Seq(0.001)\n",
    "// the value of tolerance\n",
    "val Tol: Seq[Double] = Seq(1e-6)\n",
    "// finally, elastic network parameter\n",
    "val ElasticNetParam: Seq[Double] = Seq(1)\n",
    "\n",
    "// Create an LinerRegression estimator\n",
    "val model = new LinearRegression()\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setLabelCol(\"label\")\n",
    "\n",
    "// Building the Pipeline for transformations and predictor\n",
    "println(\"Building ML pipeline\")\n",
    "val pipeline = new Pipeline().setStages(Preprocessing.stringIndexerStages :+ Preprocessing.assembler :+ model)\n",
    "\n",
    "// ***********************************************************\n",
    "println(\"Preparing K-fold Cross Validation and Grid Search: Model tuning\")\n",
    "// ***********************************************************\n",
    "\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(model.maxIter, MaxIter)\n",
    "  .addGrid(model.regParam, RegParam)\n",
    "  .addGrid(model.tol, Tol)\n",
    "  .addGrid(model.elasticNetParam, ElasticNetParam)\n",
    "  .build()\n",
    "\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(new RegressionEvaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setNumFolds(numFolds)\n",
    "\n",
    "// ************************************************************\n",
    "println(\"Training model with Linear Regression algorithm\")\n",
    "// ************************************************************\n",
    "val cvModel = cv.fit(Preprocessing.trainingData)\n",
    "\n",
    "// Save the workflow\n",
    "cvModel.write.overwrite().save(\"model/Log_LR_model\")\n",
    "\n",
    "// **********************************************************************\n",
    "println(\"Evaluating model on train and validation set and calculating RMSE\")\n",
    "// **********************************************************************\n",
    "\n",
    "val trainPredictionsAndLabels = cvModel.transform(Preprocessing.trainingData).select(\"label\", \"prediction\")\n",
    "  .map { case Row(label: Double, prediction: Double) => (label, prediction) }.rdd\n",
    "\n",
    "val validPredictionsAndLabels = cvModel.transform(Preprocessing.validationData).select(\"label\", \"prediction\")\n",
    "  .map { case Row(label: Double, prediction: Double) => (label, prediction) }.rdd  \n",
    "\n",
    "val trainRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)\n",
    "val validRegressionMetrics = new RegressionMetrics(validPredictionsAndLabels)\n",
    "val bestModel = cvModel.bestModel.asInstanceOf[PipelineModel]\n",
    "\n",
    "val results = \"\\n=====================================================================\\n\" +\n",
    "  s\"Param trainSample: ${Preprocessing.initialSample}\\n\" +\n",
    "  s\"Param testSample: ${Preprocessing.initialSample}\\n\" +\n",
    "  s\"TrainingData count: ${Preprocessing.trainingData.count}\\n\" +\n",
    "  s\"ValidationData count: ${Preprocessing.validationData.count}\\n\" +\n",
    "  s\"TestData count: ${Preprocessing.testData.count}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Param maxIter = ${MaxIter.mkString(\",\")}\\n\" +\n",
    "  s\"Param numFolds = ${numFolds}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Training data MSE = ${trainRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Training data RMSE = ${trainRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Training data R-squared = ${trainRegressionMetrics.r2}\\n\" +\n",
    "  s\"Training data MAE = ${trainRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Training data Explained variance = ${trainRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Validation data MSE = ${validRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Validation data RMSE = ${validRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Validation data R-squared = ${validRegressionMetrics.r2}\\n\" +\n",
    "  s\"Validation data MAE = ${validRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Validation data Explained variance = ${validRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\\n\" +\n",
    "  s\"CV params explained: ${cvModel.explainParams}\\n\" +\n",
    "  s\"GBT params explained: ${bestModel.stages.last.asInstanceOf[LinearRegressionModel].explainParams}\\n\" +\n",
    "  \"\\n=====================================================================\\n\"\n",
    "println(results)\n",
    "\n",
    "    val model_columns = Preprocessing.featureCols\n",
    "    val stages = bestModel.stages\n",
    "    val coefficients = stages(2).asInstanceOf[LinearRegressionModel].coefficients.toArray\n",
    "    val intercept = stages(2).asInstanceOf[LinearRegressionModel].intercept\n",
    "    val coefficient_value = model_columns zip coefficients\n",
    "    for (i<- 0 to 12){\n",
    "        println(coefficient_value(i))\n",
    "    }\n",
    "\n",
    "\n",
    "// *****************************************\n",
    "// Now see if we can predict values in our test data\n",
    "// Generate predictions using our linear regression model for all features in our test data\n",
    "println(\"Run prediction on the test set\")\n",
    "\n",
    "val fullPredictions = cvModel.transform(Preprocessing.testData).cache()\n",
    "\n",
    "// This basically adds a \"prediction\" column to our testDF dataframe\n",
    "\n",
    "// Extract the predictions and the \"known\" correct labels\n",
    "val testPredictionsAndLabels = fullPredictions.select(\"prediction\", \"label\").rdd.map(x => (x.getDouble(0), x.getDouble(1)))\n",
    "\n",
    "// Print out the predicted and actual values for each point\n",
    "/*\n",
    "for (prediction <- testPredictionsAndLabels) {\n",
    "  println(prediction)\n",
    "}\n",
    "*/\n",
    "\n",
    "val testRegressionMetrics = new RegressionMetrics(testPredictionsAndLabels)\n",
    "val testresults = \"\\n=====================================================================\\n\" +\n",
    "  s\"Test data MSE = ${testRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Test data RMSE = ${testRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Test data R-squared = ${testRegressionMetrics.r2}\\n\" +\n",
    "  s\"Test data MAE = ${testRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Test data Explained variance = ${testRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\"\n",
    "println(testresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Linear Regression with Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object Preprocessing\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object Preprocessing {\n",
    "    // Shuffling and preparing the data\n",
    "    var initialSample = 1.0\n",
    "    val wrangledData = \"Assessment_2_Wrangled.csv\"\n",
    "    val spark = SparkSessionCreate.createSession()\n",
    "    \n",
    "    import spark.implicits._\n",
    "\n",
    "    val dataInput = spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(customSchema)\n",
    "        .format(\"com.databricks.spark.csv\")\n",
    "        .load(wrangledData)\n",
    "    \n",
    "    // DATA ARRANGEMENT BEFORE THE SPLIT\n",
    "    // ============================================\n",
    "    \n",
    "    println(\"Preparing data for before the training\")\n",
    "    val dataArrange1 = dataInput.withColumn(\"property_code\", when(col(\"property_type\") === \"house\", lit(\"3\").cast(IntegerType))\n",
    "          .when(col(\"property_type\") === \"hotel\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange2 = dataArrange1.withColumn(\"room_code\", when(col(\"room_type\") === \"Entire home/apt\", lit(\"3\").cast(IntegerType))\n",
    "          .when(col(\"room_type\") === \"Private room\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange3 = dataArrange2.withColumn(\"bed_type_code\", when(col(\"bed_type\") === \"real bed\", lit(\"3\").cast(IntegerType))\n",
    "          .otherwise(lit(\"1\").cast(IntegerType)))\n",
    "\n",
    "    val dataArrange4 = dataArrange3.withColumn(\"cancellation_code\", when(col(\"cancellation_policy\") === \"strict\", lit(\"1\").cast(IntegerType))\n",
    "          .when(col(\"cancellation_policy\") === \"moderate\", lit(\"2\").cast(IntegerType))\n",
    "          .otherwise(lit(\"3\").cast(IntegerType)))\n",
    "\n",
    "    \n",
    "    // Taking logarithm of selected fields and their INTERACTIONS which are considered in our proposal and EDA work\n",
    "    val dataLog1 = dataArrange4.withColumn(\"log_estimated_annual_revenue\", log10(\"estimated_annual_revenue\"))\n",
    "    \n",
    "    // INTERACTIONS\n",
    "    // logarithm of interactions\n",
    "    val dataLog2 = dataLog1.withColumn(\"log_extra_amenities\",  log(($\"kitchen\"+$\"washer\")*($\"wifi\"+$\"cable_tv\")))    \n",
    "    val dataLog3 = dataLog2.withColumn(\"log_review_rating\", log10($\"review_scores_rating\"*$\"number_of_reviews\")) \n",
    "    \n",
    "    // interactions\n",
    "    val dataInt1 = dataLog3.withColumn(\"accom_vs_amenities\", $\"accommodates\"/(($\"beds\"/$\"bedrooms\")+$\"bathrooms\"))\n",
    "    val dataInt2 = dataInt1.withColumn(\"property_index\", $\"property_code\"*$\"room_code\")\n",
    "\n",
    "    // Filtering the data and remove rows we have defined in our EDA work\n",
    "    // Step 01:\n",
    "    val dataFilt = dataInt2.filter(!(dataInt2(\"no_bedrooms\") === 1 && dataInt2(\"amenities\") === 111 && dataInt2(\"price\") > 7500))\n",
    "\n",
    "    // Step 02:\n",
    "    var amenitiesList = List(211, 311)\n",
    "    val dataFiltered = dataFilt.filter(!(dataFilt(\"no_bedrooms\") === 3 && dataFilt(\"amenities\").isin(amenitiesList:_*) && dataFilt(\"price\") > 5000))\n",
    "\n",
    "\n",
    "    val dataDrop = dataFiltered.drop(\"property_type\", \"room_type\", \"cable_tv\",\"listing_id\",\n",
    "                                     \"bed_type\", \"cancellation_policy\", \"kitchen\", \"wifi\", \"cable_tv\", \"washer\",\n",
    "                                     \"host_response_rate\", \"city\", \"estimated_annual_revenue\",\n",
    "                                     \"accommodates\", \"beds\", \"price\", \"property_code\",\"room_code\",\n",
    "                                     \"bedrooms\", \"review_scores_rating\", \"number_of_reviews\", \"price\")    \n",
    "\n",
    "    var data = dataDrop.withColumnRenamed(\"log_estimated_annual_revenue\", \"label\").sample(false, initialSample)\n",
    "    var DF = data.na.drop()\n",
    "\n",
    "    // Null check\n",
    "    if (data == DF) println(\"No null values in the DataFrame\")\n",
    "    else {\n",
    "        println(\"Null values exist in the DataFrame\")\n",
    "        data = DF\n",
    "    }\n",
    "\n",
    "    println(data.printSchema())\n",
    "    data.select(\"zipcode\", \"label\", \"property_index\", \"accom_vs_amenities\", \"log_extra_amenities\",\n",
    "                \"log_review_rating\", \"availability_365\").show()\n",
    "\n",
    "    // ============================================\n",
    "    // TWO-STAGE SPLITTING \n",
    "    // ============================================\n",
    "    \n",
    "    // 1) Split the training data as train (training + validation) and test data\n",
    "    val seed = 12345L\n",
    "    val splits01 = data.randomSplit(Array(0.75, 0.25), seed)\n",
    "    val (trainData, testData) = (splits01(0), splits01(1))               \n",
    "    \n",
    "    // 2) Split the train data as training and validation data\n",
    "    val splits02 = trainData.randomSplit(Array(0.8, 0.2), seed)\n",
    "    val (trainingData, validationData) = (splits02(0), splits02(1))\n",
    "\n",
    "\n",
    "    // Caching all data for faster in-memory access\n",
    "    trainingData.cache\n",
    "    validationData.cache\n",
    "    testData.cache\n",
    "    \n",
    "    // ============================================\n",
    "    // DATA PIPELINE ARRANGEMENT\n",
    "    // ============================================\n",
    "\n",
    "    // Identify the categorical columns\n",
    "    def isCateg(c: String): Boolean = c matches \"zipcode\"\n",
    "\n",
    "    def categNewCol(c: String): String = if (isCateg(c)) s\"idx_${c}\" else c\n",
    "\n",
    "    // Function to select only feature columns (omit id and label)\n",
    "    def onlyFeatureCols(c: String): Boolean = !(c matches \"id|label|zipcode\")\n",
    "\n",
    "    // Definitive set of feature columns\n",
    "    val featureCols = trainingData.columns\n",
    "        .filter(onlyFeatureCols)\n",
    "        .map(categNewCol)\n",
    "\n",
    "    // StringIndexer for categorical columns (OneHotEncoder should be evaluated as well)\n",
    "    val stringIndexerStages = trainingData.columns.filter(isCateg)\n",
    "      .map(c => new StringIndexer()\n",
    "      .setInputCol(c)\n",
    "      .setOutputCol(categNewCol(c))\n",
    "      .fit(dataInput.select(c)))    \n",
    "    \n",
    "      // VectorAssembler for training features\n",
    "      val assembler = new VectorAssembler()\n",
    "        .setInputCols(featureCols)\n",
    "        .setOutputCol(\"features\")\n",
    "    // ============================================    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ML pipeline\n",
      "Preparing data for before the training\n",
      "Null values exist in the DataFrame\n",
      "root\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      " |-- no_bedrooms: integer (nullable = true)\n",
      " |-- amenities: integer (nullable = true)\n",
      " |-- bed_type_code: integer (nullable = true)\n",
      " |-- cancellation_code: integer (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- log_extra_amenities: double (nullable = true)\n",
      " |-- log_review_rating: double (nullable = true)\n",
      " |-- accom_vs_amenities: double (nullable = true)\n",
      " |-- property_index: integer (nullable = true)\n",
      "\n",
      "()\n",
      "+-------+------------------+--------------+------------------+-------------------+------------------+----------------+\n",
      "|zipcode|             label|property_index|accom_vs_amenities|log_extra_amenities| log_review_rating|availability_365|\n",
      "+-------+------------------+--------------+------------------+-------------------+------------------+----------------+\n",
      "|   2093| 4.316473583615084|             9|               1.5| 0.6931471805599453|               2.0|             321|\n",
      "|   2010| 3.727622577969137|             6|               1.0| 1.3862943611198906| 4.421603926869831|             316|\n",
      "|   2041| 5.124504224834283|             9|2.6666666666666665| 0.6931471805599453|3.1583624920952498|              69|\n",
      "|   2088| 4.396548037987132|             9|               0.8| 0.6931471805599453| 4.314077991779213|             187|\n",
      "|   2015| 5.101083443474392|             9|               1.4| 0.6931471805599453|2.7466341989375787|              32|\n",
      "|   2026| 4.771183126939401|             9|               2.0| 0.6931471805599453|3.2962262872611605|             124|\n",
      "|   2026| 4.806708948105538|             9|               2.0| 0.6931471805599453|2.9907826918031377|              43|\n",
      "|   2015| 4.373371817181301|             6|               1.0| 0.6931471805599453|  3.95525468282018|              50|\n",
      "|   2126|3.9271136119337604|             6|               0.8| 0.6931471805599453|3.6246945312720813|             270|\n",
      "|   2031| 4.545801757159277|             9|               2.0| 0.6931471805599453|2.3010299956639813|             225|\n",
      "|   2036| 4.620760489994206|             9|               1.5| 0.6931471805599453| 4.313445370426414|              17|\n",
      "|   2011| 4.660210698204069|             9|1.7142857142857142| 0.6931471805599453| 4.379142286647321|             226|\n",
      "|   2089|3.0034605321095067|             6|               0.5| 0.6931471805599453|3.8932622858879915|             353|\n",
      "|   2024| 4.552607386294613|             9|1.3333333333333333| 0.6931471805599453| 3.186391215695493|             244|\n",
      "|   2076|2.8926510338773004|             6|               0.5| 0.6931471805599453|3.2420442393695508|             354|\n",
      "|   2041|3.7781512503836434|             9|1.8000000000000003| 1.3862943611198906|2.8715729355458786|             350|\n",
      "|   2026| 4.753368539509981|             9|               1.6| 1.3862943611198906|3.7535830588929064|              13|\n",
      "|   2026| 3.591064607026499|             9|               2.0| 1.3862943611198906|3.8687619582120503|             339|\n",
      "|   2010| 4.856039754610081|             9|               1.0| 0.6931471805599453|3.0704073217401198|              79|\n",
      "|   2026| 4.793441132977663|             9|               2.0| 1.3862943611198906|2.6384892569546374|              90|\n",
      "+-------+------------------+--------------+------------------+-------------------+------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Preparing K-fold Cross Validation and Grid Search: Model tuning\n",
      "Training model with Linear Regression algorithm\n",
      "Evaluating model on train and validation set and calculating RMSE\n",
      "\n",
      "=====================================================================\n",
      "Param trainSample: 1.0\n",
      "Param testSample: 1.0\n",
      "TrainingData count: 258\n",
      "ValidationData count: 65\n",
      "TestData count: 113\n",
      "=====================================================================\n",
      "Param maxIter = 1000\n",
      "Param numFolds = 10\n",
      "=====================================================================\n",
      "Training data MSE = 0.10179915448877587\n",
      "Training data RMSE = 0.3190597976693019\n",
      "Training data R-squared = 0.6759620691020394\n",
      "Training data MAE = 0.23463441284015507\n",
      "Training data Explained variance = 0.4179974111538762\n",
      "=====================================================================\n",
      "Validation data MSE = 0.09758058717694196\n",
      "Validation data RMSE = 0.31237891602498075\n",
      "Validation data R-squared = 0.6668996853769786\n",
      "Validation data MAE = 0.2306639273639829\n",
      "Validation data Explained variance = 0.3660118723935261\n",
      "=====================================================================\n",
      "\n",
      "CV params explained: estimator: estimator for selection (current: pipeline_c6c50ae4444f)\n",
      "estimatorParamMaps: param maps for the estimator (current: [Lorg.apache.spark.ml.param.ParamMap;@7d1e10a4)\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validated metric (current: regEval_852f76b31fa8)\n",
      "numFolds: number of folds for cross validation (>= 2) (default: 3, current: 10)\n",
      "seed: random seed (default: -1191137437)\n",
      "GBT params explained: aggregationDepth: suggested depth for treeAggregate (>= 2) (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty (default: 0.0, current: 1.0)\n",
      "epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. (default: 1.35)\n",
      "featuresCol: features column name (default: features, current: features)\n",
      "fitIntercept: whether to fit an intercept term (default: true)\n",
      "labelCol: label column name (default: label, current: label)\n",
      "loss: The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError) (default: squaredError)\n",
      "maxIter: maximum number of iterations (>= 0) (default: 100, current: 1000)\n",
      "predictionCol: prediction column name (default: prediction)\n",
      "regParam: regularization parameter (>= 0) (default: 0.0, current: 0.001)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto) (default: auto)\n",
      "standardization: whether to standardize the training features before fitting the model (default: true)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0) (default: 1.0E-6, current: 1.0E-6)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0 (undefined)\n",
      "\n",
      "=====================================================================\n",
      "\n",
      "(bathrooms,0.21408490443379266)\n",
      "(availability_365,-0.003923986565675566)\n",
      "(no_bedrooms,0.006886572342095968)\n",
      "(amenities,-3.5630138034712706E-4)\n",
      "(bed_type_code,0.26216729384496884)\n",
      "(cancellation_code,-0.05488552866173838)\n",
      "(log_extra_amenities,0.0458743588798167)\n",
      "(log_review_rating,0.03663392253017807)\n",
      "(accom_vs_amenities,0.12310519552243379)\n",
      "(property_index,0.10648275587858169)\n",
      "Run prediction on the test set\n",
      "\n",
      "=====================================================================\n",
      "Test data MSE = 0.10862675992211535\n",
      "Test data RMSE = 0.3295857398646297\n",
      "Test data R-squared = 0.7314735713613659\n",
      "Test data MAE = 0.24119541385678564\n",
      "Test data Explained variance = 0.3731394788279127\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numFolds: Int = 10\n",
       "MaxIter: Seq[Int] = List(1000)\n",
       "RegParam: Seq[Double] = List(0.001)\n",
       "Tol: Seq[Double] = List(1.0E-6)\n",
       "ElasticNetParam: Seq[Double] = List(1.0)\n",
       "model: org.apache.spark.ml.regression.LinearRegression = linReg_d9175e658861\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_c6c50ae4444f\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlinReg_d9175e658861-elasticNetParam: 1.0,\n",
       "\tlinReg_d9175e658861-maxIter: 1000,\n",
       "\tlinReg_d9175e658861-regParam: 0.001,\n",
       "\tlinReg_d9175e658861-tol: 1.0E-6\n",
       "})\n",
       "cv: org.apache.spark.ml.tuning.CrossValidator = cv_da02916ea3dc\n",
       "cvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_da02916ea3dc\n",
       "trainPredictionsAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[2232] at rdd at <console>:139\n",
       "validPredictionsAndLabels..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "Logger.getLogger(\"akka\").setLevel(Level.OFF)\n",
    "\n",
    "// Defining hyperparameters \n",
    "// number of folds for cross-validation\n",
    "val numFolds = 10\n",
    "// number of maximum iteration\n",
    "val MaxIter: Seq[Int] = Seq(1000)\n",
    "// regression parameter\n",
    "val RegParam: Seq[Double] = Seq(0.001)\n",
    "// the value of tolerance\n",
    "val Tol: Seq[Double] = Seq(1e-6)\n",
    "// finally, elastic network parameter\n",
    "val ElasticNetParam: Seq[Double] = Seq(1)\n",
    "\n",
    "// Create an LinerRegression estimator\n",
    "val model = new LinearRegression()\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setLabelCol(\"label\")\n",
    "\n",
    "// Building the Pipeline for transformations and predictor\n",
    "println(\"Building ML pipeline\")\n",
    "val pipeline = new Pipeline().setStages(Preprocessing.stringIndexerStages :+ Preprocessing.assembler :+ model)\n",
    "\n",
    "// ***********************************************************\n",
    "println(\"Preparing K-fold Cross Validation and Grid Search: Model tuning\")\n",
    "// ***********************************************************\n",
    "\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(model.maxIter, MaxIter)\n",
    "  .addGrid(model.regParam, RegParam)\n",
    "  .addGrid(model.tol, Tol)\n",
    "  .addGrid(model.elasticNetParam, ElasticNetParam)\n",
    "  .build()\n",
    "\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(new RegressionEvaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setNumFolds(numFolds)\n",
    "\n",
    "// ************************************************************\n",
    "println(\"Training model with Linear Regression algorithm\")\n",
    "// ************************************************************\n",
    "val cvModel = cv.fit(Preprocessing.trainingData)\n",
    "\n",
    "// Save the workflow\n",
    "cvModel.write.overwrite().save(\"model/Log_LR_with_interactions_model\")\n",
    "\n",
    "// **********************************************************************\n",
    "println(\"Evaluating model on train and validation set and calculating RMSE\")\n",
    "// **********************************************************************\n",
    "\n",
    "val trainPredictionsAndLabels = cvModel.transform(Preprocessing.trainingData).select(\"label\", \"prediction\")\n",
    "  .map { case Row(label: Double, prediction: Double) => (label, prediction) }.rdd\n",
    "\n",
    "val validPredictionsAndLabels = cvModel.transform(Preprocessing.validationData).select(\"label\", \"prediction\")\n",
    "  .map { case Row(label: Double, prediction: Double) => (label, prediction) }.rdd  \n",
    "\n",
    "val trainRegressionMetrics = new RegressionMetrics(trainPredictionsAndLabels)\n",
    "val validRegressionMetrics = new RegressionMetrics(validPredictionsAndLabels)\n",
    "val bestModel = cvModel.bestModel.asInstanceOf[PipelineModel]\n",
    "\n",
    "val results = \"\\n=====================================================================\\n\" +\n",
    "  s\"Param trainSample: ${Preprocessing.initialSample}\\n\" +\n",
    "  s\"Param testSample: ${Preprocessing.initialSample}\\n\" +\n",
    "  s\"TrainingData count: ${Preprocessing.trainingData.count}\\n\" +\n",
    "  s\"ValidationData count: ${Preprocessing.validationData.count}\\n\" +\n",
    "  s\"TestData count: ${Preprocessing.testData.count}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Param maxIter = ${MaxIter.mkString(\",\")}\\n\" +\n",
    "  s\"Param numFolds = ${numFolds}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Training data MSE = ${trainRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Training data RMSE = ${trainRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Training data R-squared = ${trainRegressionMetrics.r2}\\n\" +\n",
    "  s\"Training data MAE = ${trainRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Training data Explained variance = ${trainRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\" +\n",
    "  s\"Validation data MSE = ${validRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Validation data RMSE = ${validRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Validation data R-squared = ${validRegressionMetrics.r2}\\n\" +\n",
    "  s\"Validation data MAE = ${validRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Validation data Explained variance = ${validRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\\n\" +\n",
    "  s\"CV params explained: ${cvModel.explainParams}\\n\" +\n",
    "  s\"GBT params explained: ${bestModel.stages.last.asInstanceOf[LinearRegressionModel].explainParams}\\n\" +\n",
    "  \"\\n=====================================================================\\n\"\n",
    "println(results)\n",
    "\n",
    "    val model_columns = Preprocessing.featureCols\n",
    "    val stages = bestModel.stages\n",
    "    val coefficients = stages(2).asInstanceOf[LinearRegressionModel].coefficients.toArray\n",
    "    val intercept = stages(2).asInstanceOf[LinearRegressionModel].intercept\n",
    "    val coefficient_value = model_columns zip coefficients\n",
    "    for (i<- 0 to 9){\n",
    "        println(coefficient_value(i))\n",
    "    }\n",
    "\n",
    "// *****************************************\n",
    "// Now see if we can predict values in our test data\n",
    "// Generate predictions using our linear regression model for all features in our test data\n",
    "println(\"Run prediction on the test set\")\n",
    "\n",
    "val fullPredictions = cvModel.transform(Preprocessing.testData).cache()\n",
    "\n",
    "// This basically adds a \"prediction\" column to our testDF dataframe\n",
    "\n",
    "// Extract the predictions and the \"known\" correct labels\n",
    "val testPredictionsAndLabels = fullPredictions.select(\"prediction\", \"label\").rdd.map(x => (x.getDouble(0), x.getDouble(1)))\n",
    "\n",
    "// Print out the predicted and actual values for each point\n",
    "/*\n",
    "for (prediction <- testPredictionsAndLabels) {\n",
    "  println(prediction)\n",
    "}\n",
    "*/\n",
    "\n",
    "val testRegressionMetrics = new RegressionMetrics(testPredictionsAndLabels)\n",
    "val testresults = \"\\n=====================================================================\\n\" +\n",
    "  s\"Test data MSE = ${testRegressionMetrics.meanSquaredError}\\n\" +\n",
    "  s\"Test data RMSE = ${testRegressionMetrics.rootMeanSquaredError}\\n\" +\n",
    "  s\"Test data R-squared = ${testRegressionMetrics.r2}\\n\" +\n",
    "  s\"Test data MAE = ${testRegressionMetrics.meanAbsoluteError}\\n\" +\n",
    "  s\"Test data Explained variance = ${testRegressionMetrics.explainedVariance}\\n\" +\n",
    "  \"=====================================================================\\n\"\n",
    "println(testresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Stop the session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
